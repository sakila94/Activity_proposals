{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "\n",
    "import cPickle as pkl\n",
    "\n",
    "import h5py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "\n",
    "from sparseprop.feature import C3D as FeatHelper\n",
    "from sparseprop.utils import get_typical_durations\n",
    "from sparseprop.train import learn_class_independent_model\n",
    "from sparseprop.train import learn_class_induced_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_filename = '/mnt/data/Proposals/labels.csv'\n",
    "feature_filename = '/mnt/data/c3d_features/feature.c3d.hdf5'\n",
    "model_filename= 'output.pkl'\n",
    "dict_size=256, \n",
    "dict_type='induced'\n",
    "dataset_filename=None\n",
    "verbose=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################################################################\n",
    "    # Prepare input/output files.\n",
    "    ###########################################################################\n",
    "    # Reading training file.\n",
    "if not os.path.exists(train_filename):\n",
    "    raise RuntimeError('Please provide a valid train file: not exists')\n",
    "train_df = pd.read_csv(train_filename, sep=',')\n",
    "rfields = ['video-name', 'f-init', 'n-frames', 'video-frames', 'label-idx']\n",
    "efields = np.unique(train_df.columns)\n",
    "if not all([field in efields for field in rfields]):\n",
    "    raise RuntimeError('Please provide a valid train file: bad formatting')\n",
    "# Feature file sanity check.\n",
    "with h5py.File(feature_filename) as fobj:\n",
    "    # Checks that feature file contains all the videos in train_filename.\n",
    "    evideos = fobj.keys()\n",
    "    rvideos = np.unique(train_df['video-name'].values)\n",
    "    if not all([x in evideos for x in rvideos]):\n",
    "        raise RuntimeError(('Please provide a valid feature file: '\n",
    "                            'some videos are missing.'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          3698\n",
       "1           796\n",
       "2          2491\n",
       "3           407\n",
       "4          1956\n",
       "5          1247\n",
       "6          2724\n",
       "7           172\n",
       "8         49142\n",
       "9          3327\n",
       "10          720\n",
       "11       138163\n",
       "12         3672\n",
       "13         1216\n",
       "14       165892\n",
       "15          455\n",
       "16           65\n",
       "17          702\n",
       "18         5563\n",
       "19        86682\n",
       "20         2368\n",
       "21         5456\n",
       "22          717\n",
       "23         4801\n",
       "24         1342\n",
       "25          448\n",
       "26         5889\n",
       "27         3396\n",
       "28          157\n",
       "29         4675\n",
       "          ...  \n",
       "39590      2739\n",
       "39591       756\n",
       "39592       648\n",
       "39593     13530\n",
       "39594      1045\n",
       "39595     15342\n",
       "39596      1713\n",
       "39597       979\n",
       "39598       548\n",
       "39599       488\n",
       "39600     49397\n",
       "39601       348\n",
       "39602       157\n",
       "39603       614\n",
       "39604       879\n",
       "39605      2444\n",
       "39606       752\n",
       "39607       116\n",
       "39608       122\n",
       "39609     37763\n",
       "39610      1313\n",
       "39611      2183\n",
       "39612       281\n",
       "39613       669\n",
       "39614       240\n",
       "39615       735\n",
       "39616     34075\n",
       "39617       205\n",
       "39618      3719\n",
       "39619         0\n",
       "Name: n-frames, Length: 39620, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['n-frames']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(df, hdf5_filename, n_clusters=256, \n",
    "                 output_filename=None, verbose=True):\n",
    "\n",
    "    # Avoid re-computing if dataset exists.\n",
    "    if output_filename:\n",
    "        if os.path.exists(output_filename):\n",
    "            with open(output_filename, 'rb') as fobj:\n",
    "                return pkl.load(fobj)\n",
    "    \n",
    "    # Iterate over each annotation instance and load its features.\n",
    "    video_lst, label_lst, feat_lst = [], [], []\n",
    "    feat_obj = FeatHelper(hdf5_filename)\n",
    "    feat_obj.open_instance()\n",
    "    for k, row in df.iterrows():\n",
    "      \n",
    "        this_feat = feat_obj.read_feat(row['video-name'],\n",
    "                                        row['f-init'],\n",
    "                                     int(row['n-frames']))\n",
    "        feat_lst.append(this_feat)\n",
    "        label_lst.append(np.repeat(row['label-idx'], this_feat.shape[0]))\n",
    "        video_lst.append(np.repeat(row['video-name'], this_feat.shape[0]))\n",
    "#         except:\n",
    "#             if verbose:\n",
    "#                 print ('Warning: instance from video '\n",
    "#                        '{} was discarded.').format(row['video-name'])\n",
    "    \n",
    "    # Stack features in a matrix.\n",
    "    feat_stack = np.vstack(feat_lst)\n",
    "    \n",
    "    # Compute KMeans centers.\n",
    "    km = KMeans(n_clusters=n_clusters, n_jobs=-1)\n",
    "    n_samples = np.minimum(1e4, feat_stack.shape[0])\n",
    "    sidx = np.random.permutation(np.arange(feat_stack.shape[0]))[:n_samples]\n",
    "    km.fit(feat_stack[sidx, :])\n",
    "    \n",
    "    # Pack dataset in a dictionary.\n",
    "    dataset = {'feat': feat_stack,\n",
    "               'label': np.hstack(label_lst),\n",
    "               'video-name': np.hstack(video_lst),\n",
    "               'centers': km.cluster_centers_}\n",
    "    \n",
    "    # Save if desired.\n",
    "    if output_filename:\n",
    "        with open(output_filename, 'wb') as fobj:\n",
    "            pkl.dump(dataset, fobj)\n",
    "            \n",
    "    return dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Preprocessing] Starting to preprocess the dataset...\n",
      "[1, 17, 33, 49, 65, 81, 97, 113, 129, 145, 161, 177, 193, 209, 225, 241, 257, 273, 289, 305, 321, 337, 353, 369, 385, 401, 417, 433, 449, 465, 481, 497, 513, 529, 545, 561, 577, 593, 609, 625, 641, 657, 673, 689, 705, 721, 737, 753, 769]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Index (257) out of range (0-250)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mValueError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-c89b9a7b87e4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# Get dataset.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m dataset = load_dataset(train_df, feature_filename, n_clusters=dict_size, \n\u001b[0;32m---> 11\u001b[0;31m                        output_filename=dataset_filename, verbose=verbose)\n\u001b[0m",
      "\u001b[0;32m<ipython-input-5-989041369831>\u001b[0m in \u001b[0;36mload_dataset\u001b[0;34m(df, hdf5_filename, n_clusters, output_filename, verbose)\u001b[0m\n\u001b[1;32m     16\u001b[0m         this_feat = feat_obj.read_feat(row['video-name'],\n\u001b[1;32m     17\u001b[0m                                      \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'f-init'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m                                      int(row['n-frames']))\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0mfeat_lst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthis_feat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mlabel_lst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'label-idx'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthis_feat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/data/Proposals/sparseprop/sparseprop/feature.py\u001b[0m in \u001b[0;36mread_feat\u001b[0;34m(self, video_name, f_init, duration, return_reshaped)\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;31m#print f_init\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m             \u001b[0;32mprint\u001b[0m \u001b[0mframes_of_interest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m             \u001b[0mfeat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvideo_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeat_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mframes_of_interest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mf_init\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mnot\u001b[0m \u001b[0mduration\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/home/sakila/anaconda3/envs/my_py2/lib/python2.7/site-packages/h5py/_hl/dataset.pyc\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    474\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    475\u001b[0m         \u001b[0;31m# Perform the dataspace selection.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 476\u001b[0;31m         \u001b[0mselection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdsid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    477\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    478\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mselection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnselect\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/sakila/anaconda3/envs/my_py2/lib/python2.7/site-packages/h5py/_hl/selections.pyc\u001b[0m in \u001b[0;36mselect\u001b[0;34m(shape, args, dsid)\u001b[0m\n\u001b[1;32m     88\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m                 \u001b[0msel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFancySelection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m                 \u001b[0msel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0msel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/sakila/anaconda3/envs/my_py2/lib/python2.7/site-packages/h5py/_hl/selections.pyc\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    384\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_id\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect_none\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvector\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margvector\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 386\u001b[0;31m             \u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscalar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_handle_simple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvector\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    387\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_id\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect_hyperslab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mh5s\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSELECT_OR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    388\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/sakila/anaconda3/envs/my_py2/lib/python2.7/site-packages/h5py/_hl/selections.pyc\u001b[0m in \u001b[0;36m_handle_simple\u001b[0;34m(shape, args)\u001b[0m\n\u001b[1;32m    449\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 451\u001b[0;31m                 \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_translate_int\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlength\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    452\u001b[0m                 \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/sakila/anaconda3/envs/my_py2/lib/python2.7/site-packages/h5py/_hl/selections.pyc\u001b[0m in \u001b[0;36m_translate_int\u001b[0;34m(exp, length)\u001b[0m\n\u001b[1;32m    469\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    470\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m<=\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m<\u001b[0m\u001b[0mlength\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 471\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Index (%s) out of range (0-%s)\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlength\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    472\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    473\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mexp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Index (257) out of range (0-250)"
     ]
    }
   ],
   "source": [
    "\n",
    "###########################################################################\n",
    "    # Preprocessing.\n",
    "###########################################################################\n",
    "if verbose:\n",
    "    print '[Preprocessing] Starting to preprocess the dataset...'\n",
    "# Remove ambiguous segments in train dataframe.\n",
    "train_df = train_df[train_df['label-idx']!=-1].reset_index(drop=True)\n",
    "# Get dataset.\n",
    "dataset = load_dataset(train_df, feature_filename, n_clusters=dict_size, \n",
    "                       output_filename=dataset_filename, verbose=verbose)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['durations'] = get_typical_durations(train_df['n-frames'])\n",
    "# Normalize KMeans centers.\n",
    "dataset['centers'] = normalize(dataset['centers'], axis=1, norm='l2')\n",
    "dataset['feat'] = normalize(dataset['feat'], axis=1, norm='l2')\n",
    "# Unifying matrix definitions.\n",
    "X, D_0 = dataset['feat'], dataset['centers']\n",
    "Y = LabelBinarizer().fit_transform(dataset['label'])\n",
    "if verbose:\n",
    "    print '[Preprocessing] Dataset sucessfully loaded and pre-proccessed.'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
